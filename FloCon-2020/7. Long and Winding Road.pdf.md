The Long & Winding Road to "Production-Worthy"
Emily Heath, PhD DHS HSSEDI FFRDC Operated by the MITRE Corporation

The Homeland Security Systems Engineering and Development Institute (HSSEDITM) is a trademark of the U.S. Department of Homeland Security (DHS). The HSSEDI FFRDC is managed and operated by The MITRE Corporation for DHS.

This Photo by Unknown Author is licensed under CC BY-SA-NC

|2|
Acknowledgement for DHS Sponsored Tasks
The Homeland Security Act of 2002 (Section 305 of PL 107-296, as codified in 6 U.S.C. 185), herein referred to as the "Act," authorizes the Secretary of the Department of Homeland Security (DHS), acting through the Under Secretary for Science and Technology, to establish one or more federally funded research and development centers (FFRDCs) to provide independent analysis of homeland security issues. MITRE Corp. operates the Homeland Security Systems Engineering and Development Institute (HSSEDI) as an FFRDC for DHS under contract HSHQDC-14-D-00006. The HSSEDI FFRDC provides the government with the necessary systems engineering and development expertise to conduct complex acquisition planning and development; concept exploration, experimentation and evaluation; information technology, communications and cyber security processes, standards, methodologies and protocols; systems architecture and integration; quality and performance review, best practices and performance measures and metrics; and, independent test and evaluation activities. The HSSEDI FFRDC also works with and supports other federal, state, local, tribal, public and private sector organizations that make up the homeland security enterprise. The HSSEDI FFRDC's research is undertaken by mutual consent with DHS and is organized as a set of discrete tasks. This report presents the results of research and analysis conducted under: 70RNPP19FR0000012 Cybersecurity and Infrastructure Security Agency (CISA) Cybersecurity Division Network Security Deployment (NSD) The purpose of the task is to provide systems engineering, integration, acquisition, program management, and cyber security subject matter expertise to define, develop, and deploy NCPS across the Federal Departments and Agencies (D/As) (the .gov domain). The results presented in this report do not necessarily reflect official DHS opinion or policy.
Approved for Public Release; Distribution Unlimited. Case Number 19-3612 / DHS reference number 70RNPP19FR0000012-02

| 3| 3| |
Problem Introduction
 Fraudulent domains: malicious domains posing as well-known
services or websites ­ Commonly used by APT & criminal groups for phishing attacks and
delivering malware
 Ex: DarkHotel APT group used microsoft-xpupdate[.]com and
adobearm[.]com to target political leaders in Asia ­ Content of domain is often identical or nearly-identical to legitimate
webpage
 Same logos, templates, fonts, images, color schemes, etc.

 How can we reliably detect these* types of domains?
*generic fraudulent domains, not domains unique to an organization's threat profile

This Photo by Unknown Author is licensed under CC BY-SA-NC

| 4| 4| |

FraudDomains v1.0

 Idea: Fraudulent & masquerading domains are more likely to
contain certain words (targeted services/brands, `update,' `download,' etc.)
­ List of 37 key terms from expertise & analysis of malicious domains

Match Results for Corpus of 65,625 Fraudulent Domains

Number of Matches

Count

Percent

[1, )

50648

77.18

[2, )

18606

28.35

[3, )

6490

9.89

[4, )

2321

3.54

[5, )

875

1.33

 v1.0 looks for these key terms after filtering with whitelist

| 5| 5| |

FraudDomains v1.5

 Idea: Extend the reach of v1.0 by adding shingle matching
­ Shingle: trigram of characters, form list by taking the set of all trigrams from key term list (105 shingles)

Match Results for Corpus of 65,625 Fraudulent Domains

Number of Matches

Count

Percent

[0,4] [5, ) [6, )

57673 7952 5770

87.88 12.12
8.79

[7, ) [8, )

4244

6.47

3146

4.79

Method

Number of Domains Flagged

Full Match Only 11301

Shingle Match Only 647

Full or Shingle Match

7952

 v1.5 looks for key terms or shingles, either can trigger a result

| 6| 6| |
FraudDomains v2.0
 Idea: Incorporate machine learning model to extend reach of v1.5

Method

Number of Domains Flagged

BNB Model Only 9688

Match Scheme Only 373

BNB & Match

5049

 Plot twist: operational
testing showed v1.5 was noisier than anticipated (too many FPs) ­ New plan: use BNB model
as first-pass filter

| 7| 7| |

v2.0 Major Problem 1: False Positives
 Additional operational testing showed v2.0 was frequently marking
cloud/CDN domains as malicious ­ Result: LOTS of alerts when running on real DNS traffic ­ Solution: implement a second whitelist filter looking for identified patterns

Domain from
"query" field in DNS traffic

In

whitelist

No

of known

benign

domains?

Yes

Cloud/ CDN pattern match?

Labelled

No

benign by

BNB

model?

Yes

Yes

Return "benign" result

Below

No

threshold

for full or

shingle

matches?

Yes No

Return "malicious"
result

| 8| 8| |
v2.0 Major Problem 2: Scaling
 Integration testing showed FraudDomains could process around
~4.5 domains per second ­ Doesn't stand a chance in production: average load is ~23K per second
 Goal: Get close to 1.9K domains per second

To find a solution, we need to first find the problem

Improve integration
testing

Review code

cProfile

lineprofiler

| 9| 9| |
Using cProfile

| 1| 010| |
Using line_profiler

| 1| 111| |
The Changes We Tried Along the Way
 Profiling showed Naïve Bayes computation was expensive
(A Very Not-to-Scale) Domains/Second Progress Chart

0
~4.5 domains/second
v2.0 as is

~14 domains/second
Binarizing the input in advance

Goal: 1900

~12.2 domains/second
Using a hashing vectorizer instead of a count vectorizer

~24.3 domains/second
Computing the underlying math in numexpr instead of numpy

 The scale of these changes was insufficient

| 1| 212| |
Arriving at v3.0
 Lessons we learned: math is hard  New plan: do less math!
­ Switched to logistic regression model: ~1600 domains/second This Photo by Unknown Author is licensed under CC BY

Method
Log Model Only Match Scheme Only Log & Match

Number of Domains Flagged 10823 246 5176

 Bonus perk: thresholding
on probability

| 1| 313| |
A Miscellaneous Details Detour
 Pytest is great, and pytest as part of a CI/CD pipeline is an actual
lifesaver ­ Pylint is a nightmare useful too

 Version control is your friend
­ Code, packages, data & models

This Photo by Unknown Author is licensed under CC BY-NC-ND

 Obligatory comment about Docker
This Photo by Unknown Author is licensed under CC BY-SA-NC

| 1| 414| |
Conclusions
 There are many aspects of performance to consider for an analytic
­ Experimental results demonstrate an initial path forward ­ Operational results expose unforeseen weaknesses
 Writing good software is hard (for me)
­ Robust testing & tools to dig into the code help identify areas that can be modified/improved/fixed
 Keep on keepin' on
­ Continuously evaluate the analytic to find opportunities for refinements, enhancements, improvements

