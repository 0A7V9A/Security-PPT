#RSAC
SESSION ID: MLAI-M01
Assessing Vendor AI Claims Like a Data Scientist, Even if You Aren't One
Joshua Saxe
Chief Scientist Sophos Twitter: @joshua_saxe

#RSAC
Disclaimer
Presentations are intended for educational purposes only and do not replace independent professional judgment. Statements of fact and opinions expressed are those of the presenters individually and, unless expressly stated to the contrary, are not the opinion or position of RSA Conference LLC or any other cosponsors. RSA Conference does not endorse or approve, and assumes no responsibility for, the content, accuracy or completeness of the information presented. Attendees should note that sessions may be audio- or video-recorded and may be published in various media, including print, audio and video formats without further notice. The presentation template and any media capture are subject to copyright protection.
©2022 RSA Conference LLC or its affiliates. The RSA Conference logo and other trademarks are proprietary. All rights reserved.
2

#RSAC
Presentation structure
Why do we need this talk? How machine learning works in theory How security machine learning works in practice Questions to ask a vendor and what good answers look like Where to go from here
3

#RSAC
Why do we need this talk?

Why do we need this talk?
Next-generation artificial intelligence
Source: https://memes.com/

#RSAC
5

#RSAC
How machine learning works in theory

#RSAC
How does machine learning-based detection work?
"Learned" decision boundary
7

#RSAC
Machine learning geometry operates in high dimensional spaces
Every pixel in images could get a "dimension" Every field in file headers could get a dimension Every word in a language could get a dimension
8

#RSAC
Simple machine learning ideas operating in high dimensions can yield impressive results
https://pjreddie.com/darknet/yolo/ (Credit:Joseph Redmon, Ali Farhadi) 9

#RSAC
Security machine learning in the real world
What matters most about building effective AI systems

#RSAC
Common myths about what matters in security machine learning
Myth: Mathematical sophistication is what drives accuracy Myth: The learning algorithm used is what drives accuracy Myth: Original ideas, beyond what's already public knowledge, are what drive accuracy Myth: Machine learning supersedes signatures, allowlists and blocklists
11

#RSAC
What actually matters in security machine learning
Reality: Timely real-world data and data volumes drive accuracy Reality: Correct data labels drive accuracy Reality: An evaluation that accurately estimates how well a given approach will actually work drives accuracy Reality: You can't deploy machine learning well without including signatures, allowlists, and blocklists
12

#RSAC
Why signatures, blocklists and allowlists need to be deployed alongside machine learning

Signature / allowlist

"Learned" decision boundary
13

#RSAC
How to (politely) interrogate a security machine learning team

#RSAC
The security machine learning workflow

Data engineering
ETL engineering Data fusion
Label definition

Research
Literature review
Evaluation definition and implementation
Feature selection

Integration

Operations

Integration of inference into larger detection pipeline

Continuous model evaluation

Integration of feedback into data architecture

Maintenance of model retraining and evaluation toolchain

Discussion and planning with product stakeholders

Model retraining

Data and label fusion

Mathematical modeling

Integration engineering

Retrained model packaging

Cloud / database engineering

Labeling and data engineering improvements

Integration testing

Staged retrained model deployment
15

#RSAC
The security machine learning workflow

Data engineering
ETL engineering Data fusion
Label definition

Research
Literature review
Evaluation definition and implementation
Feature selection

Data and label fusion Cloud / database engineering

Mathematical modeling
Labeling and data engineering improvements

Integration

Operations

Integration of inference into larger detection pipeline

Continuous model evaluation

Integration of feedbacks into data architecture

Maintenance of model retraining and evaluation toolchain

Discussion and planning with
prTodhuicst stiaskewhohldearst people

Model
usually

retraining

focus on

Integration engineering

Retrained model packaging

Integration testing

Staged retrained model deployment
16

#RSAC
The security machine learning workflow

Data engineering
ETL engineering Data fusion
Label definition

Research
Literature review
Evaluation definition and implementation
Feature selection

Data and label fusion Cloud / database engineering

Mathematical modeling
Labeling and data engineering improvements

Integration
Integration of inference into larger detection pipeline
Integration of feedbacks into data architecture
Discussion and planning with product stakeholders

Operations
Continuous model evaluation
Maintenance of model retraining and evaluation toolchain
Model retraining

Integration engineering

Retrained model packaging

Integration testing

Staged retrained model deployment
17

#RSAC
The security machine learning workflow

Data engineering

Research

Integration

Operations

ETL engineering Data fusion
Label definition Data and label fusion Cloud / database engineering

Literature review

Integration of inference into larger detection pipeline

Continuous model evaluation

Where do you get your training data from and why do you think it's

Evaluation definition and

Integration of feedbacks into

Maintenance of model retraining

implementation representativedoatfa tahrcehitdecatutrae I'll see on myanndeetvwaluoatrikon?toolchain

How do
Feature selection

you

know

wDishcuastsiognoaondd palanndninbgawdithlook produectvsatalukeahtoilodenrsdata?

like

in

your training
Model retraining

and

Mathematical Hmoodwelindgo you fuse dInatetgaraftrioonmengmineuelrtinipgle sourcesRetotrayinieedldmotdheel pbacekasgting training and evaluation data?

Labeling and data engineering improvements

Integration testing

Staged retrained model deployment

18

#RSAC
The security machine learning workflow

Data engineering
ETL engineering Data fusion
Label definition

Research
Literature review
Evaluation definition and implementation
Feature selection

Data and label fusion Cloud / database engineering

Mathematical modeling
Labeling and data engineering improvements

Integration

Operations

Integration of infeWrenhceeinrteo can larger detectionapilpgeloinerithms

I read about the Continuous model evaluation
you're using on

Wikipedia?

Integration of feedbacks into

Maintenance of model retraining

data architecture

and evaluation toolchain

What was the evaluation process

that led Discussion and planning with product stakeholders

you

toMpoidcekl reytroainuinrg

approach?

Integration engineering

Retrained model packaging

Can I see the evaluations you did

on your
Integration testing

system wStahgeidleretyraoinued wmoederle developingdietp?loyment

19

#RSAC
The security machine learning workflow

Data engineering

Research

ETL engineering

Literature review

How do you combine your system

witDhataa flulsoiownsilgisntast,ubrleosc?klisEvtaslu,imaatpiolnenmddeenfitnaittiioonn and

HowLaibselydeofiunitrionsystem architeFceatteurde steolection

get feedback from operational

sDeattatainndglasbesl ofusiiotncan improMvaetheomvaeticral modeling

time?

Cloud / database engineering

Labeling and data engineering improvements

Integration
Integration of inference into larger detection pipeline
Integration of feedbacks into data architecture
Discussion and planning with product stakeholders

Operations
Continuous model evaluation
Maintenance of model retraining and evaluation toolchain
Model retraining

Integration engineering

Retrained model packaging

Integration testing

Staged retrained model deployment
20

#RSAC
The security machine learning workflow

Data engineering

Research

Integration

ETL engineering

Literature review

Integration of inference into larger detection pipeline

How do you monitor the accuracy of your system in

Data fusion

deEpvallouimaytpimolenmdeeennfitnatitt?iioonn and

Integration of feedbacks into data architecture

HowLabehl adevfienitiyonou dealt with aFecatcuurersaeleccytiocnrises operDaistcpuiorsosindounactalnsltdyakp?elahnonldinegrswith

HDaotawandolafbteel fnusiodno you retraMiantheamnatdicarl meoddeelipngloy your sIyntsetgreatmion?engineering What triggers training and redeployment?

Cloud / database engineering

Labeling and data engineering improvements

Integration testing

Operations
Continuous model evaluation
Maintenance of model retraining and evaluation toolchain
Model retraining
Retrained model packaging
Staged retrained model deployment
21

#RSAC
Takeaways
Effective security ML isn't mostly about math! Timely realworld data and data volumes drive accuracy The key to effective security ML is an evaluation that accurately estimates how well a given approach will actually work You can't deploy machine learning well without including signatures, allowlists, and blocklists Grill security vendors about all this!
22

#RSAC
Applying the lessons of this presentation
Immediate actions you can take
­ Use notes from this presentation to grill AI-focused security vendors ­ Use notes from this presentation to think about your own detection-
oriented work
Actions you can take in the next three months
­ Learn more about real-world machine learning; read Malware Data Science (Saxe & Sanders)
­ If you operate machine learning technology, refocus on your main levers: data and data label quality + operational hygiene
23

