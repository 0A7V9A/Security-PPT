SESSION ID: MLAI-F03
Designing Trustworthy AI: A User Experience (UX) Framework
Carol J. Smith
Sr. Research Scientist - Human-Machine Interaction Carnegie Mellon University's Software Engineering Institute Twitter: @carologic @sei_etc

#RSAC

#RSAC
Legal
Copyright 2020 Carnegie Mellon University. This material is based upon work funded and supported by the Department of Defense under Contract No. FA8702-15-D-0002 with Carnegie Mellon University for the operation of the Software Engineering Institute, a federally funded research and development center. NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN "ASIS" BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT. [DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution. Please see Copyright notice for non-US Government use and distribution. DM20-0086
2

#RSAC
AI's Great Promise
Empower us with knowledge Augment our effectiveness
We can--and must--ensure that we keep humans safe and in control

#RSAC
Lack of Trust in Artificial Intelligence (AI)
Inadequate and abusive work

#RSAC
Assuming That Math Reduces Bias
Vetting applicant resumes

#RSAC
Embedding Existing Bad Behaviors
Determining interest rates for mortgage lenders

#RSAC
Dehumanizing thru Math
Predicting future criminal activity

Bias in Training Set
Training Set

#RSAC
Data Encountered

8

#RSAC
How can development teams create AI systems that are safe and trustworthy?

#RSAC
Today ­ Make Trustworthy AI Systems
Technology ethics and bias Team qualities that lead to success User Experience (UX) Framework Checklist and Agreement to support work

#RSAC
Technology Ethics

Ethics
Based on well-founded standards of right and wrong
Standard of expected behavior that guides the correct course of action
What impact does my work have?
What is Ethics? By Manuel Velasquez, Claire Andre, Thomas Shanks, S.J., and Michael J. Meyer. Markkula Center for Applied Ethics https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/what-is-ethics/

#RSAC

#RSAC
Not Trolley Problems (hypotheticals in-the-moment)
MIT Moral Machine Project
Images: 1) MIT Moral Machine Project: http://moralmachine.mit.edu/ 2) Does the Trolley Problem Have a Problem? https://slate.com/technology/2018/06/psychologystrolley-problem-might-have-a-problem.html

#RSAC
This is early, purposeful work
Not just about code Challenging work about conduct, interactions, intents Start with technology ethics Benefits
­ Harmonize cultural variations ­ Balance to pace of change, industry pressure ­ Explicit permission to consider and question breadth of implications

#RSAC
Adopt Technology Ethics
What do you value? What lines won't you cross? Track progress

#RSAC
16

#RSAC
AI "does not remove the responsibility from people... What is new about AI does not change human responsibility."
- Michael McQuade
Defense Innovation Advisory Board member and VP for research at Carnegie Mellon University
17

#RSAC
"When you know better, you do better."
- Betty Easterly
Be aware and informed.

#RSAC
Bias

Data Design Solution

#RSAC
...are biased

#RSAC
Due to team member's...
Social class Resource availability Education Race, gender, sexuality Culture, theology, tradition More...

#RSAC
Bias: Human's Mental Shortcut
Not inherently bad, may be misapplied Implicit = invisible (intuition) Not necessarily in sync with conscious beliefs Can be managed and changed
Graphic by Karen Bachmann as presented in: https://www.slideshare.net/karenbachmann/know-thyself-understanding-and-managing-biases

#RSAC
Start with building awareness and knowing ourselves
How are our biases affecting our work?

#RSAC
Team Qualities for Trustworthy AI

#RSAC
What is a diverse team?
Gender, race, culture, education (school, program, etc.), thinking process, disability status, and more...

Image: https://www.flickr.com/photos/byrawpixel/45739276192/in/photostream/ Created with love by rawpixel.com. Download this image in high resolution under Creative Commons 0 at www.rawpixel.com.

#RSAC
Diverse, Talented and Multi-Disciplinary

Includes skill set and problem framing approach

Data Scientists

Not lowering bar ­ extending it

Machine learning experts

Programmers

System architects

Product managers, etc.

(context dependent)

#RSAC
Curiosity Experts
Understand
­ Situation ­ Abilities of people who will use system ­ How system will be used
Activate curiosity in others via UX activities
Social scientists, ethicists and more...

#RSAC
Why diverse teams?
Focus more on facts Process facts more carefully More innovative
"...become more aware of their own potential biases"
Why Diverse Teams Are Smarter. Harvard Business Review. https://hbr.org/2016/11/why-diverse-teams-are-smarter

#RSAC
Great Minds Think Different

#RSAC
Inclusive Workplace Requirements
Representatively diverse leadership = retention Individuals differences are acknowledged and accepted
­ Bring "whole selves" to work ­ Welcoming community environment ­ Feel valued, connected, that we belong
30

#RSAC
Coalesce on Shared Set of Technology Ethics
1. Well-being 2. Respect for autonomy 3. Protection of privacy and intimacy 4. Solidarity 5. Democratic participation 6. Equity 7. Diversity inclusion 8. Prudence 9. Responsibility 10. Sustainable development
Montréal Declaration for a responsible development of artificial intelligence. https://www.montrealdeclaration-responsibleai.com/the-declaration

Diverse,

#RSAC

inclusive

leaders

Diverse, MultiDisciplinary Teams

Shared Tech Ethics

#RSAC
UX Framework
Designing Trustworthy AI

How do we get there?
?

#RSAC
Trustable, Ethical AI

Montréal Declaration for a responsible development of artificial intelligence. https://www.montrealdeclaration-responsibleai.com/the-declaration

#RSAC
Conversations for Understanding
UX Framework guides AI development teams Difficult Topics
­ What do we value? ­ Who could be hurt? ­ What lines won't our AI cross? ­ How are we shifting power?* ­ How will we track our progress?
*"How is this ML model shifting power?" @riakall #NeurIPS2019

#RSAC
"Be uncomfortable"
- Laura Kalbag
Ethical design is not superficial.

#RSAC
UX Framework for Designing Trustworthy AI
Accountable to humans

Honest and usable

Ethical AI

Cognizant of speculative risks
and benefits

Respectful and secure

Accountable to Humans
Ensure humans have ultimate control
­ Able to monitor and control risk
Human responsibility for final decisions
­ Person's life ­ Quality of life ­ Health ­ Reputation

#RSAC

Accountable to humans

Honest and usable

Ethical AI

Speculative

Respectful and secure

"Ensure humans can unplug the machines" #RSAC
­ Grady Booch
TED Talk, Grady Booch, Scientist, Philosopher, IBM'er
https://www.ted.com/talks/grady_booch_don_t_fear_superintelligence

#RSAC
Cognizant of Speculative Risks and Benefits
Identify full range of
­ Harmful, malicious use, as well as good, beneficial use ­ Blind spots and unwanted/unintended consequences

Accountable to humans

Honest and usable

Ethical AI

Speculative

Respectful and secure

#RSAC
Speculative: Conduct UX research and activate curiosity
Abusability Testing
Speculate about misuse and abuse Create "Black Mirror" episodes
­ Severe abuse and consequences
Template by: Anna Abovyan & Allison Cosby, IxDA Pittsburgh, Sep 2019

#RSAC
Speculative: Create communication & mitigation plans
Plan for unwanted consequences
Misuse and abuse of AI system
­ Who can report? ­ To whom? ­ Turn off? ­ Who notified? ­ Consequences?

#RSAC
Respectful and Secure

Values of humanity, ethics, equity, fairness, accessibility, diversity and inclusion

Respect privacy and data rights

Make system robust, valid and reliable

Provide understandable security

Accountable to humans

Honest and usable

Ethical AI

Speculative

Respectful and secure

#RSAC
Fair: Remove unwanted bias in data
Show awareness of known and desirable bias Acknowledge issues Overcommunicate on issues

#RSAC
Honest and Usable
Value transparency with the goal of engendering trust Explicitly state identity as an AI system

Accountable to humans

Honest and usable

Ethical AI

Speculative

Respectful and secure

#RSAC
UX Framework: Being intentional, keeping people safe
Accountable to humans

Honest and usable

Ethical AI

Cognizant of speculative risks
and benefits

Respectful and secure

#RSAC
Checklist and Agreement
Designing Trustworthy AI

#RSAC
Checklist and Agreement
Pair with Tech Ethics
­ Bridge gap between "do no harm" and reality
Reduce risk and unwanted bias Mitigation planning Support inspection
Checklist and Agreement - Downloadable PDF:
https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=636620

#RSAC
Prompts for Conversations

#RSAC
Reward team members for finding ethics bugs
Dr. Ayanna Howard - on the Artificial Intelligence Podcast with Lex Fridman
50

#RSAC
Evangelize for human values Ethical. Transparent. Fair.

#RSAC
We aren't perfect, AI won't be perfect

Diverse teams, inclusive environments

Adopt tech ethics

Encourage deep conversations (Checklist)

Activate curiosity; be speculative; imaginative Make trustworthy AI systems

Accountable to humans

Honest and usable

Ethical AI

Speculative

Respectful and secure

#RSAC
Apply What You Have Learned Today
Next week:
­ Identify initial set of technology ethics ­ Introduce tech ethics and Checklist to 1 team*
3 months:
­ Formally adopt technology ethics based on learnings ­ Run 1+ abusability workshop ­ Expand use of Checklist
6 months:
­ Measure progress (e.g. proactiveness, quality conversations vs. surprises)
*Experime53nt to learn

SESSION ID: MLAI-F03
Designing Trustworthy AI: A UX Framework

Carol J. Smith, cjsmith@sei.cmu.edu
Sr. Research Scientist - Human-Machine Interaction Carnegie Mellon University's Software Engineering Institute Twitter: @carologic @sei_etc
SEI on HMT: https://sei.cmu.edu/research-capabilities/all-work/display.cfm?customel_datapageid_4050=197910

#RSAC

#RSAC
Resources
Designing Trustworthy AI

#RSAC
56

#RSAC
Resources
Black Mirror, Light Mirror: Teaching Technology Ethics Through Speculation. Casey Fiesler. Oct 15, 2018. https://howwegettonext.com/the-black-mirror-writers-room-teaching-technology-ethics-throughspeculation-f1a9e2deccf4 UX in the Age of Abusability. The role of Composition, Collaboration, and Craft in building ethical products. Dan Brown. Sep 18, 2018. https://greenonions.com/ux-in-the-age-of-abusability797cd01f6b13 AI Now 2017 Report, New York University, and AI Now https://assets.ctfassets.net/8wprhhvnpfc0/1A9c3ZTCZa2KEYM64Wsc2a/8636557c5fb14f2b74b2be64c3 ce0c78/_AI_Now_Institute_2017_Report_.pdf "How IBM is Competing with Google in AI." The Information. https://www.theinformation.com/howibm-is-competing-with-google-in-ai?eu=2zIDMNYNjDp7KqL4YqAXXA "The business case for augmented intelligence" by Nancy Pearson, VP Marketing, IBM Cognitive. https://medium.com/cognitivebusiness/the-business-case-for-augmented-intelligence36afa64cd675#.qqzvunakw "Inside Intel: The Race for Faster Machine Learning" http://www.intel.com/content/www/us/en/analytics/machine-learning/the-race-for-faster-machinelearning.html

#RSAC
More Resources
"Update: Why this week's man-versus-machine Go match doesn't matter (and what does)" by Dana Mackenzie. Science Magazine. Mar. 15, 2016 http://www.sciencemag.org/news/2016/03/update-whyweek-s-man-versus-machine-go-match-doesn-t-matter-and-what-does "For IBM's CTO for Watson, not a lot of value in replicating the human mind in a computer." by Frederic Lardinois (@fredericl), TechCrunch, Posted Feb 27, 2017. https://techcrunch.com/2017/02/27/for-ibmscto-for-watson-not-a-lot-of-value-in-replicating-the-human-mind-in-a-computer/ "Google and IBM: We Want Artificial Intelligence to Help You, Not Replace You" Most Powerful Women by Michelle Toh. Mar 02, 2017. Fortune. http://fortune.com/2017/03/02/google-ibm-artificialintelligence/ "Facebook scales back AI flagship after chatbots hit 70% f-AI-lure rate - 'The limitations of automation`" by Andrew Orlowski. Feb 22, 2017. The Register https://www.theregister.co.uk/2017/02/22/facebook_ai_fail/ "Microsoft is deleting its AI chatbot's incredibly racist tweets" by Rob Price. Mar. 24, 2016. Business Insider UK. http://www.businessinsider.com/microsoft-deletes-racist-genocidal-tweets-from-aichatbot-tay-2016-3

#RSAC
Even More Resources
"IBM's Automated Radiologist Can Read Images and Medical Records" by Tom Simonite, February 4, 2016. Intelligent Machines, MIT Technology Review. https://www.technologyreview.com/s/600706/ibms-automated-radiologist-can-read-images-andmedical-records/ "The IBM, Salesforce AI Mash-Up Could Be a Stroke of Genius" by Adam Lashinsky, Mar 07, 2017. Fortune. http://fortune.com/2017/03/07/data-sheet-ibm-salesforce/ "Google can now tell you're not a robot with just one click" by Andy Greenberg. Dec. 3, 2014. Security: Wired. https://www.wired.com/2014/12/google-one-click-recaptcha/ "Essentials of Machine Learning Algorithms (with Python and R Codes)" by Sunil Ray, August 10, 2015. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2015/08/common-machine-learningalgorithms/ IBM on Machine Learning https://www.ibm.com/analytics/us/en/technology/machine-learning/ "At Davos, IBM CEO Ginni Rometty Downplays Fears of a Robot Takeover" by Claire Zillman, Jan 18, 2017. Fortune. http://fortune.com/2017/01/18/ibm-ceo-ginni-rometty-ai-davos/ "Google and IBM: We Want Artificial Intelligence to Help You, Not Replace You" by Michelle Toh. Mar 02, 2017. Fortune. http://fortune.com/2017/03/02/google-ibm-artificial-intelligence/

#RSAC
Yes, even more resources
Video: "IBM Watson Knowledge Studio: Teach Watson about your unstructured data" https://www.youtube.com/watch?v=caIdJjtvX1s&t=6s "The optimist's guide to the robot apocalypse" by Sarah Kessler, @sarahfkessler. March 09, 2017. QZ. https://qz.com/904285/the-optimists-guide-to-the-robot-apocalypse/ "AI Influencers 2017: Top 30 people in AI you should follow on Twitter" by Trips Reddy @tripsy, Senior Content Manager, IBM Watson . February 10, 2017 https://www.ibm.com/blogs/watson/2017/02/aiinfluencers-2017-top-25-people-ai-follow-twitter/ "3 guiding principles for ethical AI, from IBM CEO Ginni Rometty" by Alison DeNisco. January 17, 2017, Tech Republic http://www.techrepublic.com/article/3-guiding-principles-for-ethical-ai-from-ibm-ceoginni-rometty/ "Transparency and Trust in the Cognitive Era" January 17, 2017 Written by: IBM THINK Blog https://www.ibm.com/blogs/think/2017/01/ibm-cognitive-principles/ "Ethics and Artificial Intelligence: The Moral Compass of a Machine" by Kris Hammond, April 13, 2016. Recode. http://www.recode.net/2016/4/13/11644890/ethics-and-artificial-intelligence-the-moralcompass-of-a-machine

#RSAC
Last bit: I promise
"The importance of human innovation in A.I. ethics" by John C. Havens. Oct. 03, 2015 http://mashable.com/2015/10/03/ethicsartificial-intelligence/#yljsShvAFsqy "Me, Myself and AI" Fjordnet Limited 2017 - Accenture Digital. https://trends.fjordnet.com/trends/me-myself-ai "Testing AI concepts in user research" By Chris Butler, Mar 2, 2017. https://uxdesign.cc/testing-ai-concepts-in-user-researchb742a9a92e55#.58jtc7nzo "CMU prof says computers that can 'see' soon will permeate our lives" by Aaron Aupperlee. March 16, 2017. http://triblive.com/news/adminpage/12080408-74/cmu-prof-sayscomputers-that-can-see-soon-will-permeate-our-lives

